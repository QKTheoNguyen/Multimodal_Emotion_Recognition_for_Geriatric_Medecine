{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44601517",
   "metadata": {},
   "source": [
    "# Metadata preprocessing\n",
    "\n",
    "Run this script to preprocess the datasets and to create a metadata file, once you have downloaded them into the `data/EmoData` folder.\n",
    "\n",
    "## EmoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54139f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02baeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "emo_data_dir = os.path.join(data_dir, \"EmoData\")\n",
    "EmoDB_dir = os.path.join(emo_data_dir, \"EmoDB\")\n",
    "wav_dir = os.path.join(EmoDB_dir, \"wav\")\n",
    "metadata_filepath = os.path.join(data_dir, \"metadata_emo_EmoDB.csv\")\n",
    "\n",
    "EmoDict_german = {\n",
    "    'W': 'anger',\n",
    "    'L': 'boredom',\n",
    "    'A': 'fear',\n",
    "    'F': 'joy',\n",
    "    'T': 'sadness',\n",
    "    'E': 'disgust',\n",
    "    'N': 'neutral',\n",
    "}\n",
    "\n",
    "# comment the following line if the metadata file already exists\n",
    "metadata_new = pd.DataFrame({'filepath': [],\n",
    "                            'speaker': [],\n",
    "                            'gender': [],\n",
    "                            'emotion': [],\n",
    "                            'utterance_id': []})\n",
    "\n",
    "for file in os.listdir(wav_dir):\n",
    "    speaker = file[:2]\n",
    "    utterance_id = file[2:5]\n",
    "    emotion_letter = file[5]\n",
    "    emotion = EmoDict_german[emotion_letter]\n",
    "    filepath = os.path.join('EmoDB', 'wav', file)\n",
    "\n",
    "    new_row = pd.DataFrame({'filepath': [filepath],\n",
    "                            'speaker': [speaker], \n",
    "                            'gender': [None],\n",
    "                            'emotion': [emotion],\n",
    "                            'utterance_id': [utterance_id]})\n",
    "    \n",
    "    metadata_new = pd.concat([metadata_new, new_row])\n",
    "\n",
    "metadata_new.to_csv(metadata_filepath, index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9dc3e",
   "metadata": {},
   "source": [
    "## eNTERFACE\n",
    "\n",
    "eNTERFACE dataset is composed of video recordings of actors performing emotional speech. As we are only interested in the audio, we will extract the audio from the video files. The audio files are stored in the `data/EmoData/eNTERFACE/wav` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_array_from_video(avi_path):\n",
    "    \"\"\"\n",
    "    extract mono audio array from single .avi video. sampling rate = 44100 Hz\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    avi_path : path of the video file (.avi)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mono : mono array of audio track (nb samples,1)\n",
    "    default sampling rate\n",
    "    \"\"\"\n",
    "    \n",
    "    video = VideoFileClip(avi_path)\n",
    "    audio = video.audio\n",
    "    print(f'audio type: {type(audio)}')\n",
    "    # Extract the audio as a list of samples\n",
    "    audio_samples = list(audio.iter_frames())\n",
    "    # Convert the list of samples to a NumPy array\n",
    "    sound_array = np.array(audio_samples)\n",
    "    mono = np.mean(sound_array,axis=1) #convert to mono\n",
    "    \n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ca8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "emo_data_dir = os.path.join(data_dir, \"EmoData\")\n",
    "enterface_dir = os.path.join(emo_data_dir, \"eNTERFACE\", \"enterface database\")\n",
    "enterface_wav_dir = os.path.join(emo_data_dir, \"eNTERFACE\", \"wav\")\n",
    "\n",
    "for subject in os.listdir(enterface_dir):\n",
    "    subject_path = os.path.join(enterface_dir, subject)\n",
    "    for emotion in os.listdir(subject_path):\n",
    "        emotion_path = os.path.join(subject_path, emotion)\n",
    "        for sentence in os.listdir(emotion_path):\n",
    "            sentence_path = os.path.join(emotion_path, sentence)\n",
    "            if os.path.isdir(sentence_path):\n",
    "                for video in os.listdir(sentence_path):\n",
    "                    video_path = os.path.join(sentence_path, video)\n",
    "                    if video.endswith('.avi'):\n",
    "                        # print(f\"Processing {video_path}\")\n",
    "                        audio_filename = os.path.splitext(video)[0] + '.wav'\n",
    "                        audio_path = os.path.join(enterface_wav_dir, subject, emotion, sentence)\n",
    "                        audio_filepath = os.path.join(audio_path, audio_filename)\n",
    "                        if not os.path.exists(audio_filepath):\n",
    "                            audio_array = extract_audio_array_from_video(video_path)\n",
    "                            os.makedirs(audio_path, exist_ok=True)\n",
    "                            print(f\"Extracting audio from {video} to {audio_filename}\")\n",
    "                            wavfile.write(audio_filepath, 44100, audio_array)\n",
    "                        else:\n",
    "                            print(f\"Audio file {audio_filepath} already exists. Skipping extraction.\")\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e81e03",
   "metadata": {},
   "source": [
    "create the metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfee24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "emo_data_dir = os.path.join(data_dir, \"EmoData\")\n",
    "enterface_wav_dir = os.path.join(emo_data_dir, \"eNTERFACE\", \"wav\")\n",
    "metadata_filepath = os.path.join(data_dir, \"metadata_emo_eNTERFACE.csv\")\n",
    "metadata_new = pd.read_csv(metadata_filepath)\n",
    "\n",
    "emotion_dict = {\n",
    "    'anger': 'anger',\n",
    "    'happiness': 'joy',\n",
    "    'fear': 'fear',\n",
    "    'sadness': 'sadness',\n",
    "    'disgust': 'disgust',\n",
    "    'surprise': 'surprise',\n",
    "    'neutral': 'neutral',\n",
    "}\n",
    "\n",
    "# comment the following line if the metadata file already exists\n",
    "metadata_new = pd.DataFrame({'filepath': [],\n",
    "                            'speaker': [],\n",
    "                            'gender': [],\n",
    "                            'emotion': [],\n",
    "                            'utterance_id': []})\n",
    "\n",
    "for subject in os.listdir(enterface_wav_dir):\n",
    "    subject_path = os.path.join(enterface_wav_dir, subject)\n",
    "    for emotion in os.listdir(subject_path):\n",
    "        emotion_path = os.path.join(subject_path, emotion)\n",
    "        for sentence in os.listdir(emotion_path):\n",
    "            sentence_path = os.path.join(emotion_path, sentence)\n",
    "            if os.path.isdir(sentence_path):\n",
    "                for audio in os.listdir(sentence_path):\n",
    "                    audio_path = os.path.join(sentence_path, audio)\n",
    "                    if audio.endswith('.wav'):\n",
    "                        emotion_label = emotion_dict[emotion]\n",
    "                        speaker = subject[7:]\n",
    "                        utterance_id = sentence[8:]\n",
    "                        filepath = audio_path[13:]\n",
    "                        new_row = pd.DataFrame({'filepath': [filepath],\n",
    "                                                'speaker': [speaker], \n",
    "                                                'gender': [None],\n",
    "                                                'emotion': [emotion_label],\n",
    "                                                'utterance_id': [utterance_id]})\n",
    "                        metadata_new = pd.concat([metadata_new, new_row])\n",
    "                        \n",
    "metadata_new.to_csv(metadata_filepath, index=False)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065c32f",
   "metadata": {},
   "source": [
    "# Create split files\n",
    "\n",
    "Run this script to create the split files (train, val, test) for training and testing the models. The split files are created under the LOSGO (Leave One Speaker Group Out) or LOSO (Leave One Speaker Out) procedure.\n",
    "\n",
    "## EmoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f707c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emodb_metadata_filepath = os.path.join('data', 'metadata_emo_EmoDB.csv')\n",
    "emodb_metadata = pd.read_csv(emodb_metadata_filepath)\n",
    "\n",
    "# Select the speakers for test and validation sets\n",
    "test_speakers = [16]\n",
    "validation_speakers = [15]\n",
    "\n",
    "# create csv files for test and validation speakers metadata\n",
    "test_metadata = pd.DataFrame(columns=emodb_metadata.columns)\n",
    "validation_metadata = pd.DataFrame(columns=emodb_metadata.columns)\n",
    "train_metadata = pd.DataFrame(columns=emodb_metadata.columns)\n",
    "\n",
    "for index, row in emodb_metadata.iterrows():\n",
    "    speaker = row['speaker']\n",
    "    row = row.to_frame().T\n",
    "    if int(speaker) in test_speakers:\n",
    "        test_metadata = pd.concat([test_metadata, row])\n",
    "    elif int(speaker) in validation_speakers:\n",
    "\n",
    "        validation_metadata = pd.concat([validation_metadata, row], ignore_index=True)\n",
    "    else:\n",
    "        train_metadata = pd.concat([train_metadata, row], ignore_index=True)\n",
    "\n",
    "# shuffle the metadata files\n",
    "train_metadata = train_metadata.sample(frac=1).reset_index(drop=True)\n",
    "validation_metadata = validation_metadata.sample(frac=1).reset_index(drop=True)\n",
    "test_metadata = test_metadata.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# save the metadata files\n",
    "train_metadata.to_csv(os.path.join('data', 'train_metadata_emo_emodb.csv'), index=False)\n",
    "validation_metadata.to_csv(os.path.join('data', 'val_metadata_emo_emodb.csv'), index=False)\n",
    "test_metadata.to_csv(os.path.join('data', 'test_metadata_emo_emodb.csv'), index=False)\n",
    "print('Metadata files created successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e5252",
   "metadata": {},
   "source": [
    "## eNTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d319cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enterface_metadata_filepath = os.path.join('data', 'metadata_emo_eNTERFACE.csv')\n",
    "enterface_metadata = pd.read_csv(enterface_metadata_filepath)\n",
    "\n",
    "test_speakers = [36, 37, 38, 39]\n",
    "validation_speakers = [40, 41, 42, 43, 44]\n",
    "\n",
    "# create csv files for test and validation speakers metadata\n",
    "test_metadata = pd.DataFrame(columns=enterface_metadata.columns)\n",
    "validation_metadata = pd.DataFrame(columns=enterface_metadata.columns)\n",
    "train_metadata = pd.DataFrame(columns=enterface_metadata.columns)\n",
    "\n",
    "for index, row in enterface_metadata.iterrows():\n",
    "    speaker = row['speaker']\n",
    "    row = row.to_frame().T\n",
    "    if int(speaker) in test_speakers:\n",
    "        test_metadata = pd.concat([test_metadata, row])\n",
    "    elif int(speaker) in validation_speakers:\n",
    "\n",
    "        validation_metadata = pd.concat([validation_metadata, row], ignore_index=True)\n",
    "    else:\n",
    "        train_metadata = pd.concat([train_metadata, row], ignore_index=True)\n",
    "\n",
    "# shuffle the metadata files\n",
    "train_metadata = train_metadata.sample(frac=1).reset_index(drop=True)\n",
    "validation_metadata = validation_metadata.sample(frac=1).reset_index(drop=True)\n",
    "test_metadata = test_metadata.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# save the metadata files\n",
    "train_metadata.to_csv(os.path.join('data', 'train_metadata_emo_enterface.csv'), index=False)\n",
    "validation_metadata.to_csv(os.path.join('data', 'val_metadata_emo_enterface.csv'), index=False)\n",
    "test_metadata.to_csv(os.path.join('data', 'test_metadata_emo_enterface.csv'), index=False)\n",
    "print('Metadata files created successfully')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
